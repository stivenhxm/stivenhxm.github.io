# 产品需求文档

## 功能一：双语同传助手

### 功能概述
双语同传助手旨在为不同语言的人们提供流畅、无障碍的交流体验。它能够实时捕捉语音，翻译为目标语言，以文字和/或语音的形式输出。

### 主要功能

1. **即时语音识别**：能够快速、准确地识别用户的语音输入。
2. **双语翻译**：支持中英双向翻译，确保翻译质量达到专业标准（可扩展法语、俄语、西班牙语、阿拉伯语等语种）。
3. **分屏显示**：手机屏幕分为两部分，一边显示源语言，另一边显示翻译后的语言。
4. **语音输出选项**：除文字输出外，还支持语音播放翻译结果，帮助用户更好地理解。
5. **用户设置**：允许用户自定义如何显示和播放翻译，例如是否自动播放翻译后的语音、字体大小等。
6. **历史记录**：提供用户对话的历史记录管理功能，包括及时记录列表、详情、删除等功能。

### 应用场景

1. **商务谈判**：如中国人和外国人谈生意时，可以使用该应用进行无障碍交流。
2. **旅游导览**：旅行者在异国他乡可以使用此应用与当地人交流。
3. **国际会议**：在没有同传译员的情况下，与会者可以使用此应用进行交流。
4. **日常交往**：学习语言或与外籍朋友交往时，可使用此应用作为交流桥梁。

### 挑战和考虑因素

1. **翻译准确性**：需要选择高质量的翻译引擎，确保翻译的准确性和自然性。
2. **实时性**：确保语音识别和翻译过程的延迟尽可能小。
3. **噪音处理**：在嘈杂的环境中，如何准确识别用户的语音是一个挑战。


## 功能二：拍照翻译助手

### 功能概述
拍照翻译助手为旅行者或商务人事提供方便快捷的文字识别与翻译功能，解决在国外遇到的不熟悉文字内容问题。用户可以轻松地通过拍照或选择相册中的照片，应用即可识别图片中的文字并翻译成所选的目标语言。
可参考百度拍照翻译功能。

### 主要功能

1. **图片识别与文字替换**：用户可以通过拍摄照片或选择手机相册中的照片，应用自动识别照片中的文字内容，并将翻译后的文字替换到图片中原文字的位置，同时确保翻译文字与原文字的字体、颜色保持一致。
2. **自动检测语种**：应用能够自动检测图片中的源语言，无需用户手动选择。
3. **多语种翻译**：除中英翻译外，支持更多如法语、俄语、西班牙语、日语等常见语种的翻译。
4. **结果保存**：用户可以方便地保存翻译结果。


### 应用场景

1. **旅游导览**：当旅行者在国外遇到不认识的路牌或导向标志时，可以使用此应用进行翻译。
2. **餐饮选择**：在不熟悉的国家，用应用扫描餐厅的菜单，即可了解各个菜品的具体内容。
3. **购物助手**：在购物时扫描商品标签或说明书，帮助用户了解产品详细信息。
4. **日常交流**：与外国人交往时，扫描他们所写或展示的文字，方便进行交流。

### 挑战与考虑

1. **识别准确性**：确保应用可以准确识别各种字体、手写或印刷、以及不同背景下的文字。
2. **翻译品质**：选择高质量的翻译引擎，确保翻译的准确性和自然性。
3. **应对复杂图片**：如何处理图片中的多语言混合、或有大量非关联文本的情况。
4. **文字替换**：翻译后的文字需要和图片中原文字的背景、字体、颜色和大小融洽地结合，以及布局问题，确保看起来自然且不突兀。

## 功能三：AI口语老师(视频)

### 功能概述
AI老师视频练口语旨在通过先进的AI技术为用户提供一个仿真、实时的与英语老师进行口语对话的环境。用户可以与表现逼真的AI英语老师实时进行视频对话，得到与真实沟通类似的学习体验。
参考call annie。

### 主要特点

1. **AI老师的逼真展现**：
    - 显示高质量、逼真的AI老师视频。
    - AI老师具有丰富的表情和与语音同步的口型，为用户提供真实的交谈体验。

2. **实时交互式对话**：
    - 用户可以直接呼叫AI老师并与之进行实时对话，无需按键发送语音或文字。
    - AI老师具备高度的交互性，能够智能地与用户沟通，模仿真实的教师-学生对话情境。

3. **自定义学习体验**：
    - 用户可根据自己的需求调整AI老师的语速，适应不同的学习阶段。
    - 谈话难度可调节，以满足从初学者到高级学习者的需求。
    - 提供多种实际场景选择，如餐厅、机场、商场等，以增加学习的实际性和趣味性。

4. **多样化的AI老师角色**：
    - 用户可根据个人喜好选择不同形象和性格的AI老师，增加学习的多样性和趣味性。
      
4. **多语种支持**：
    - 支持英语、中文、法语、俄语、西班牙语、日语等常见语种。

### 应用场景

1. **基础学习**：对于英语初学者，AI老师可提供基础词汇、语法的教学和实践。
2. **情境对话**：用户可以选择特定的情境进行模拟对话，如在餐厅点餐、在机场询问航班信息等。
3. **口语测试**：用户可以进行口语能力的模拟测试，AI老师会提供反馈和建议。
4. **雅思口语**：提供雅思口语的仿真练习。
5. **日常交流**：用户可以与AI老师进行日常话题的自由交谈，提高口语流利度。

### 挑战与考虑

1. **技术实现**：如何确保AI老师视频的逼真性，以及语音、口型、表情的同步。
2. **语音识别准确性**：如何确保AI老师视频的逼真性，以及语音、口型、表情的同步。
3. **交互体验**：保证实时的语音识别与反馈，减少延迟，确保流畅的对话体验。
4. **智能引导**：AI老师如何更好地模拟真实教师的教学方法，提供有针对性的引导和反馈。


## AI口语老师(语音)
### 功能概述
通过先进的AI技术为用户提供一个与英语老师进行语音对话的环境。用户可以发送自己的语音并收到AI英语老师的即时回答，从而得到实时的英语口语练习体验。
参考talk ai。

### 主要特点

1. **用户语音输入**：
    - 用户可以点击按钮录制自己的语音，录制完成后点击发送。
    - 系统将用户的语音识别为文字并显示。

2. **AI老师的语音反馈**：
    - AI老师自动用语音回答用户的问题。
    - 与语音回答同时，也会显示相应的文字内容。

3. **语言提示功能**：
    - 当用户不知道如何继续对话时，可以使用提示功能获取话题或句型建议。

4. **语法纠正提示**：
    - APP会对用户的表达进行实时的语法纠正，提供修正建议，帮助用户更正常见的口语错误。

5. **对话历史保存**：
    - 提供对话历史的文字、语音的保存、显示、播放、删除等功能。

## 关键技术一：语音识别技术
### 语音识别技术选型考虑因素

#### 1. 准确性 
识别系统能够准确地转录语音到文字的能力。
- 能适应中国人的不标准的英语发音。
- 在嘈杂环境下的表现。
- 识别不同年龄段、性别的语音的能力。

#### 2. 实时性
系统识别并响应的速度。
- 30秒的语音，能否在500ms内完成识别
- 对话系统的流畅性要求。

#### 3. 扩展性
系统能够适应未来更多需求的能力。
- 是否可以轻松增加新的语言或功能？
- 与其他系统的集成能力。

#### 4. 成本
技术解决方案的经济考量。
- 初始投资和运营成本。
- 是否有按使用量付费的选项？
- 硬件和软件的总体拥有成本。

#### 5. 离线识别能力
在没有网络连接的情况下进行语音识别的能力。
- 是否需要在无网络环境下使用？
- 离线识别的准确性与实时性。

#### 6. 集成难度
将语音识别技术集成到现有或新的系统中的复杂性。
- SDK或API的兼容性和文档的完善度。
- 技术支持和社区活跃度。

#### 7. 技术兼容性
- 跨平台: 可以在同时支持安卓和IOS平台，手机和平台设备。

#### 8. 用户体验
- **描述**：最终用户在使用语音识别功能时的感受。
- **考虑点**：
    - 识别错误时的纠正流程。
    - 界面设计和交互性。

#### 9. 模型微调
根据特定需求或数据对预训练模型进行微调的能力。
- 是否可以使用自己的数据来微调模型？
- 数据准备和预处理的工具和流程
- 模型优化的效率和效果。

### 端侧VS云侧

#### 端侧
- 数据不需要在网络上进行传输，通常在设备性能没有瓶颈的情况下，识别速度会更快。
- 有限的计算能力可能限制了模型的大小和复杂性，一般模型在50M-100M为佳，不能超过200M。
- 支持单一语种，或中英文，扩展其他语种会困难一些；更新和维护可能更加困难，因为需要推送到每个设备。
- 初始研发成本可能较高，因为可能没有现成的能达到商用条件的模型，需要训练优化。

#### 云侧
- 需要高带宽和低延迟的网络连接；可能存在网络延迟，尤其是在不稳定的网络环境中。
- 可以使用更大、更复杂的模型，因此通常可以获得更高的准确性。
- 方便扩展多语种；可以利用最新的模型和算法，因为服务器可以经常更新。
- 有服务器运行、存储和带宽成本，可能会随着用户量的增加而增加成本

### 云侧三方API VS 云侧自建

#### 云侧三方API
- **即插即用**: 大部分三方API为即插即用，无需深入的技术集成，大大缩短了产品上线的时间。
- **稳定性**: 成熟的三方API供应商经常对其服务进行维护和更新，确保其服务稳定性和可靠性。
- **费用**: 根据API调用的次数或时长计费，可能在流量大时费用增长较快。
- **灵活性有限**: 由于是预先构建好的解决方案，可能无法满足特定的业务需求或个性化定制。
- **数据隐私**: 使用外部服务可能存在数据隐私问题，尤其是对于敏感信息。

#### 云侧自建
- **模型定制**: 能够针对产品的使用场景、用户发音特点进行模型训练、优化。
- **初始成本高**: 自建解决方案通常需要大量的初期投资，包括设备、人力和时间。
- **维护成本**: 需要持续投资时间和资源来更新、维护和改进该系统。
- **费用**: 在用户规模上来后，使用成本会降下来。
- **数据隐私**: 数据完全在公司的控制之下，更加安全。

### 流式语音识别 VS 非流式语音识别

#### 流式语音识别
- **实时性**: 能够在说话的过程中，边说话边识别，为用户提供即时的反馈。
- **资源开销**: 可能需要更多的计算资源，尤其是当处理大量并发请求时。
- **错误修正**: 在语音流还在进行时，可能难以对之前的识别错误进行修正。

#### 非流式语音识别
- **准确性**: 由于可以等待整个语音输入结束后再进行识别，通常可以采用更复杂的后处理方法来提高准确性。
- **灵活性**: 可以在用户结束语音输入后立即开始或暂停处理，便于调整和优化。
- **技术成熟**: 相比于流失语音识别，技术更加成熟。

## 关键技术二：TTS(文本转语音)
### TTS 技术选型考虑因素

1. **自然性和可懂性**:
    - 语音的产出应该是自然流畅的，听起来像真人，而不是机械或合成。
    - 良好的韵律和语调模拟，能够模拟真人的停顿、强调和语调变化。
    
2. **多语言和多口音支持**:
    - 支持多种语言和方言，以满足不同用户的需求。
    - 有能力模拟不同的口音，使得训练更具针对性。

3. **实时性**:
    - 能够在短时间内产生高质量的语音输出，为用户提供即时的反馈。

4. **个性化语音**:
    - 能够生成不同性别、年龄、声音特性的语音，以满足个性化需求。

5. **可扩展性**:
    - 有能力根据需求增加新的语音模型或进行个性化训练。

6. **成本效益**:
    - 考虑许可、API调用费用、运行成本等，确保TTS解决方案在预算内并具有成本效益。

7. **训练和调优**:
    - 是否支持使用自定义数据集进行训练，以提高特定应用的性能。
    - 调优工具和接口，允许根据特定需求进行语音输出的微调。

8. **技术兼容性**:
    - 跨平台: 可以在同时支持安卓和IOS平台，手机和平台设备。

### 端侧TTS VS 云侧TTS

#### 端侧TTS
- 低延迟: 数据不需要在网络上进行传输，通常在设备性能没有瓶颈的情况下，TTS转换速度会更快。
- 离线工作能力: 在没有网络连接的情况下也可以正常工作。
- 更新难度: 模型的更新和维护可能比较困难，因为每次更新都需要重新推送到每个用户设备。
- 多语种支持限制: 主要支持主流语种如中英文，扩展其他小众语种可能更具挑战。

#### 云侧TTS
- 网络依赖: 需要高带宽和低延迟的网络连接；在不稳定的网络环境中可能存在延迟和数据丢失的风险。
- 模型优势: 可以使用更大、更复杂的模型，因此通常能够生成更自然、更高质量的语音。
- 灵活的语种支持: 更容易支持多种语言，因为可以随时在服务器端添加新模型。
- 运营成本: 有服务器的运行、存储和带宽成本，可能会随着用户量和请求量的增加而增加成本。

## 关键技术三：数字人技术

## 数字人技术关键特性

### **1. 实时性**
- **延迟**: 在实时互动中，尽可能低的延迟是至关重要的，以确保自然的对话流畅度。
- **同步性**: 视频中的数字人的口型、表情和动作应与其语音完全同步。

### **2. 逼真性**
- **高分辨率**: 清晰、细致的图像对于逼真的视频体验至关重要。
- **真实感**: 人工智能生成的数字人应该具有逼真的皮肤纹理、眼球运动和发光效果。

### **3. 表情和身体语言**
- **丰富性**: 数字人应该能够模仿真人的各种表情和情感。
- **适应性**: 数字人的反应应该是上下文相关的，并能够根据对话的内容适当地反应。

### **4. 定制性**
- **模型多样性**: 提供不同性别、年龄、种族和外观的数字人模型。
- **服装和配件**: 允许定制数字人的服装、发型和配件。

### **5. 技术兼容性**
- **跨平台**: 数字人技术应该可以在各种设备和操作系统上运行，如智能手机、平板电脑和PC。
- **集成**: 能够与其他技术和平台无缝集成，如语音识别、自然语言处理等。

### **6. 扩展性**
- **算法更新**: 能够轻松地更新和改进数字人的算法和模型。
- **多语种支持**: 数字人应该支持多种语言和方言，以适应全球用户。

## VAD (Voice Activity Detection)技术
检测语音中人声和非人声，输出语音前后端点，指导ASR声学模型何时解码。
在视频实时对话中，用户何时输入语音，何时语音输入结束，需要VAD技术进行检测。

### **关键特性**

1. **准确性**：高准确率的VAD可以有效减少误报和漏报，从而提高整体语音识别系统的性能。
  
2. **实时性**：对于需要实时处理的应用，VAD 必须快速且延迟低。
  
3. **适应性**：能够在不同的背景噪声和声音环境中工作，如在室外、室内、车内等。
  
4. **低资源消耗**：在某些应用场景（例如嵌入式系统或移动设备）中，VAD 必须在有限的计算资源下运行。
  
5. **鲁棒性**：对突发的噪声事件或其他声音干扰具有很好的抵抗能力。

## 关键技术四：LLM（大语言模型）
无论是视频，还是语音对话，其对话的文字的理解，以及生成的对话文本，都是需要依赖LLM大语言模型。
### 大型语言模型 (LLM) 的关键特性

#### 1. **理解能力**

- **上下文感知**：模型应能够理解并维护与用户的长期对话上下文。
- **多语言支持**：对多种语言的理解，特别是如果APP目标是全球用户。
- **抽象和推理**：模型应能够进行一些基本的逻辑推理和理解抽象概念。

#### 2. **响应质量**

- **准确性**：提供的答案或指导应该是语法和事实上都正确的。
- **一致性**：对相同或类似的问题，模型的回答应保持一致。
- **自然性**：输出的语言应该听起来自然，不像是机器生成的。

#### 3. **性能**

- **实时响应**：在对话场景中，模型应能够快速响应用户的查询。
- **扩展性**：能够同时处理大量的用户请求。

#### 4. **适应性**

- **微调能力**：能够根据特定领域或应用进行模型微调。
- **持续学习**：模型应有能力从用户互动中学习并优化其回答。

#### 5. **安全性与偏见**

- **过滤不恰当内容**：模型应能够避免生成任何不适当、冒犯或有害的内容。
- **偏见识别与减少**：模型应该在回应中尽量避免偏见，并且能够对其进行监控和修正。

#### 6. **成本**

- **运行成本**：大型模型可能需要高昂的计算资源，所以运行成本应该被考虑进去。
- **训练和更新成本**：如果选择自己训练或微调模型，这也会产生额外的成本。

### OpenAI接口调用策略
如选用openai，需要考虑如何能稳定、可靠的调用其api，防止出现网络中断，或触发openai的风控机制。

#### 1. **国际云服务提供商**

- 考虑使用国际知名的云服务提供商，例如AWS、Google Cloud或Azure。它们通常在全球范围内都有数据中心。
- 在一个与OpenAI接口延迟较低的区域（例如亚太地区）设置代理服务器或中间层，将API请求从这个区域转发。

#### 2. **VPN & 专用线路**

- 为企业设置稳定的VPN服务，确保持续、稳定的外网访问。
- 考虑购买企业级的专用线路，提供稳定、高速的访问。

#### 3. **请求重试机制**

- 设计API请求时的重试机制，当遇到暂时的网络故障时，可以尝试多次请求，以提高成功率。
- 使用逐步增加的延迟时间进行重试，以避免短时间内的频繁请求。
  
#### 4. **监控与报警**

- 设立实时网络监控机制，当检测到访问OpenAI的延迟增加或失败率上升时，立即触发报警。
- 这可以确保技术团队及时了解并处理任何潜在的问题。




